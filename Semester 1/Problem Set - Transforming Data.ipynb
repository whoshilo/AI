{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593e6074",
   "metadata": {},
   "source": [
    "# Re-Expression\n",
    "\n",
    "When data is skewed, it can be hard to summarize them, and hard to decide whether the most extreme values are outliers or just part of the stretched-out tail. How can we say anything useful about such data? The secret is to re-express the data by applying a simple function to each value. ;)\n",
    "\n",
    "Many relationships and ‚Äúlaws‚Äù in the sciences and social sciences include functions such as logarithms, square roots, and reciprocals. Similar relationships often show up in data. \n",
    "\n",
    "Here‚Äôs a simple example:\n",
    "\n",
    "In 1980 CEOs made, on average, about 42 times what workers earned. In the next two decades, CEO compensation soared when compared to the average worker. By 2000 that multiple had jumped to 525 ü§Øüò±üòµ. What does the distribution of the compensation of Fortune 500 companies‚Äô CEOs look like? Here‚Äôs a histogram and boxplot for 2005 compensation:\n",
    "\n",
    "![CEO Salary Distribution](https://raw.githubusercontent.com/SSpindt/AI/main/Semester%201/Problem%20Set%20Images/CEOSalary.png)\n",
    "\n",
    "We have 500 CEOs and about 48 possible histogram bins, most of which are empty. Don‚Äôt miss the tiny bars straggling out to the right! The boxplot indicates that some CEOs received extraordinarily high compensations, while the majority received relatively ‚Äúlittle.‚Äù But look at the values of the bins. The first bin, with about half the CEOs, covers incomes from 0 dollars to 5 million dollars ü§Øüò±üòµ. \n",
    "\n",
    "The reason that the histogram seems to leave so much of the area blank is that the salaries are spread all along the axis from about fifteen million to 240 million dollars. After 50 million dollars there are so few for each bin that it‚Äôs very hard to see the tiny bars. What we can see from this histogram and boxplot is that this distribution is highly skewed to the right!\n",
    "\n",
    "It can be hard to decide what we mean by the ‚Äúcenter‚Äù of a skewed distribution, so it‚Äôs hard to pick a typical value to summarize the distribution. What would you say was a typical CEO salary? The mean value is 10,307,000, while the median is ‚Äúonly‚Äù 4,700,000. Each tells us something different about the data.\n",
    "\n",
    "One thing we can do is to **re-express** or **transform** the data in some way. More specifically, we can apply a simple function to make the the skewed distribution more symmetric. For example, we could take the square root or logarithm of each salary. Taking logs works pretty well, as you can see:\n",
    "\n",
    "![CEO Salary Distribution Rexpressed](https://raw.githubusercontent.com/SSpindt/AI/main/Semester%201/Problem%20Set%20Images/Re-expressedCeoSalary.png)\n",
    "\n",
    "The histogram of the logs of the salaries is now much more symmetric! We can see that a typical log compensation is between 6 -- which corresponds to 1,000,000 dollars -- and 7 -- corresponding to 10,000,000 dollars. And it‚Äôs easier to talk about a typical value for the logs. The mean log compensation is 6.73, while the median is 6.67. (That‚Äôs 5,370,317 dollars and 4,677,351 dollars, respectively.) Notice that nearly all the values are between 6.0 and 8.0. In other words, between 1,000,000 dollars and 100,000,000 dollars a year, but who‚Äôs counting üòõ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175bc71d",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Your Turn</span>\n",
    "Please solve the following problems using Python, Markdown, and the [2024 Spotify data set](https://drive.google.com/drive/folders/1qJlOhn_pZ8dMnV6onOt8l0bG5756Fh9d?usp=sharing) we saw a few classes ago."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce068bf",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Problem 1</span>\n",
    "First, examine the distribution of YouTube Views. Then, answer these questions:\n",
    "1. What part of this distribution makes it difficult to summarize?\n",
    "2. What would you suggest we do if we want to understand YouTube Views better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364c3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution with Python here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3761b3",
   "metadata": {},
   "source": [
    "Answer the questions with markdown here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929a1f50",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Problem 2</span>\n",
    "Re-express the YouTube Views distribution so that it is easier to summarize.\n",
    "Hint! Consider using one of these re-expression techniques:\n",
    "1. Logarithmic Transformation\n",
    "2. Square Root Transformation\n",
    "3. Reciprocal Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7765db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Numpy is a Python library that does calculations quickly and efficiently.\n",
    "\n",
    "# Re-express the distribution with Python here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb89178",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Problem 3</span>\n",
    "Take a look at your re-expression. Then, answer the following questions:\n",
    "1. Is it better to analyze the original YouTube Views or the re-expressed version of the data? Why?\n",
    "2. Write a few sentences that describes the YouTube Views distribution. What can we conclude from this distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0eb955",
   "metadata": {},
   "source": [
    "**Answer the questions with markdown here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c25ef1f",
   "metadata": {},
   "source": [
    "# Z-Scores\n",
    "The women‚Äôs heptathlon in the Olympics consists of seven track and field events: \n",
    "1. the 200-m run\n",
    "2. 800-m run\n",
    "3. 100-m high hurdles\n",
    "4. shot put\n",
    "5. javelin\n",
    "6. high jump\n",
    "7. long jump. \n",
    "\n",
    "To determine who should get the gold medal, somehow the performances in all seven events have to be combined into one score. How can performances in such different events be compared? They don‚Äôt even have the same units; the races are recorded in minutes and seconds and the throwing and jumping events in meters. In the 2004 Olympics, Austra Skujyt√© of Lithuania put the shot 16.4 meters, about 3 meters farther than the average of all contestants. Carolina Kl√ºft won the long jump with a 6.78-m jump, about a meter better than the average. Which performance deserves more points? Even though both events are measured in meters, it‚Äôs not clear how to compare them. The solution to the problem of how to compare scores turns out to be a useful method for comparing all sorts of values whether they have the same units or not.\n",
    "\n",
    "The trick in comparing very different-looking values is to use standard deviations. The standard deviation tells us how the whole collection of values varies, so it‚Äôs a natural ruler for comparing an individual value to the group.\n",
    "\n",
    "Take a look at the means and standard deviations calculated for the long jump and shot put events of the 2004 Olympics:\n",
    "![Olympic Calculations](https://raw.githubusercontent.com/SSpindt/AI/main/Semester%201/Problem%20Set%20Images/OlympicCalculations.png)\n",
    "\n",
    "Kl√ºft‚Äôs 6.78 m long jump is 0.62 meters longer than the mean jump of 6.16 m. How many standard deviations better than the mean is that? The standard deviation for this event was 0.23 m, so her jump was (6.78 - 6.16)\\\\0.23 = 0.62\\\\0.23 = 2.70 standard deviations better than the mean. Skujyt√©‚Äôs winning shot put was 16.40 - 13.29 = 3.11 meters longer than the mean shot put distance, and that‚Äôs 3.11\\\\1.24 = 2.51 standard deviations better than the mean. That‚Äôs a great performance but not quite as impressive as Kl√ºft‚Äôs long jump, which was farther above the mean, as measured in standard deviations.\n",
    "\n",
    "To compare these athletes‚Äô performances, we determined how many standard deviations from the event‚Äôs mean each was. Expressing the distance in standard deviations standardizes the performances. To standardize a value, we simply subtract the mean performance in that event and then divide this difference by the standard deviation. We can write the calculation as:\n",
    "\n",
    "![Z-Score Formula](https://raw.githubusercontent.com/SSpindt/AI/main/Semester%201/Problem%20Set%20Images/ZScoreFormula.png)\n",
    "\n",
    "These values are called \"standardized values\", and are commonly denoted with the letter z. Usually, we just call them **z-scores**. Standardized values have no units. z-scores measure the distance of each data value from the mean in standard deviations. A z-score of 2 tells us that a data value is 2 standard deviations above the mean. It doesn‚Äôt matter whether the original variable was measured in inches, dollars, or seconds. Data values below the mean have negative z-scores, so a z-score of -1.6 means that the data value was 1.6 standard deviations below the mean. Of course, regardless of the direction, the farther a data value is from the mean, the more unusual it is, so a z-score of -1.3 is more extraordinary than a z-score of 1.2. \n",
    "\n",
    "Looking at the z-scores, we can see that even though both were winning scores, Kl√ºft‚Äôs long jump with a z-score of 2.70 is slightly more impressive than Skujyt√©‚Äôs shot put with a z-score of 2.51 üëèüëèüëè.\n",
    "\n",
    "To summarize, a z-score gives us an indication of how unusual a value is because it tells us how far it is from the mean. If the data value sits right at the mean, it‚Äôs not very far at all and its z-score is 0. A z-score of 1 tells us that the data value is 1 standard deviation above the mean, while a z-score of -1 tells us that the value is 1 standard deviation below the mean. How far from 0 does a z-score have to be to be interesting or unusual? There is no universal standard, but the larger the score is (negative or positive), the more unusual it is. We know that 50% of the data lie between the quartiles. For symmetric data, the standard deviation is usually a bit smaller than the IQR, and it‚Äôs not uncommon for at least half of the data to have z-scores between - 1 and 1. But no matter what the shape of the distribution, a z-score of 3 (plus or minus) or more is rare, and a z-score of 6 or 7 deserves a second look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f720ef",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Your Turn</span>\n",
    "Please solve the following problems using Python, Markdown, and the [2024 Spotify data set](https://drive.google.com/drive/folders/1qJlOhn_pZ8dMnV6onOt8l0bG5756Fh9d?usp=sharing) we saw a few classes ago."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac7ffc1",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Problem 4</span>\n",
    "\n",
    "First, examine the distribution of TikTok Likes. Then, answer these questions:\n",
    "\n",
    "1. What is the average number of likes received on TikTok?\n",
    "2. What is the standard deviation of TikTok Likes? Remember, standard deviation should only be calculated for normal distrbutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74d56ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580eec89",
   "metadata": {},
   "source": [
    "**Your markdown here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49df63f",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Problem 5</span>\n",
    "\n",
    "Calculate the Z-score for the number of TikTok likes that *Metro Boomin's Niagara Falls (Foot or 2)* received. Now, calculate the Z-score that *Kevin MacLeod's Monkeys Spinning Monkeys* received. Finally, answer the following question:\n",
    "1. Which song received the more impressive amount of likes on TikTok?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1b6bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ac1398",
   "metadata": {},
   "source": [
    "**Your markdown here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c4c09",
   "metadata": {},
   "source": [
    "# Shifting and Rescaling\n",
    "You can **shift** the data in a distribution when you add or subtract a constant from every value in the distribution. Adding or subtracting a constant changes each data value equally, so the entire distribution just shifts. Its shape doesn‚Äôt change and neither does the spread. None of the measures of spread we‚Äôve discussed‚Äînot the range, not the IQR, not the standard deviation‚Äîchanges.\n",
    "\n",
    "You can **rescale** the data in a distribution when you multiple or divide every value in the distribution by a constant. Suppose we want to look at the weights of male individuals in pounds instead of kilograms. We‚Äôd have to rescale the data to do this. Because there are about 2.2 pounds in every kilogram, we‚Äôd convert the weights by multiplying each value by 2.2. Multiplying or dividing each value by a constant changes the measurement units. Here are histograms of the two weight distributions, plotted on the same scale, so you can see the effect of multiplying:\n",
    "\n",
    "![Rescaling Data - Histograms](https://raw.githubusercontent.com/SSpindt/AI/main/Semester%201/Problem%20Set%20Images/RescalingData.png)\n",
    "\n",
    "What happens to the shape of the distribution? Although the histograms don‚Äôt look exactly alike, we see that the shape really hasn‚Äôt changed: Both are uni- modal and skewed to the right.\n",
    "What happens to the mean? Not much -- it gets multiplied by 2.2 as well. The men weigh 82.36 kg on average, which is 181.19 pounds. As the box-plots and 5-number summaries show, all measures of position act the same way. They all get multiplied by this same constant. What happens to the spread? Take a look at the boxplots. The spread in pounds (on the right) is larger. How much larger? If you guessed 2.2 times, you‚Äôve figured out how measures of spread get rescaled.\n",
    "\n",
    "\n",
    "![Rescaling Data - Box Plot](https://raw.githubusercontent.com/SSpindt/AI/main/Semester%201/Problem%20Set%20Images/BoxPlotRescale.png)\n",
    "\n",
    "What does this mean for z-scores? When we standardize data into z-scores we are just shifting them by the mean and rescaling them by the standard deviation. Now we can see how standardizing affects the distribution! When we subtract the mean of the data from every data value, we shift the mean to zero. As we have seen, such a shift doesn‚Äôt change the standard deviation.\n",
    "When we divide each of these shifted values by s, however, the standard deviation should be divided by s as well. Since the standard deviation was s to start with, the new standard deviation becomes 1.\n",
    "How, then, does standardizing affect the distribution of a variable? Let‚Äôs consider the three aspects of a distribution: the shape, center, and spread.\n",
    "- Standardizing into z-scores does not change the shape of the distribution of a variable. \n",
    "- Standardizing into z-scores changes the center by making the mean 0.\n",
    "- Standardizing into z-scores changes the spread by making the standard deviation 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4097c0",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Your Turn</span>\n",
    "Please solve the following problems using Python, Markdown, and the latest [Spotify data set](https://drive.google.com/drive/folders/1nGqifcJXrpsEDCkAiJMnQkrGiOgD93Qv?usp=drive_link) we have been working with in the last few classes. <span style=\"color:red\">**ALERT! This is a different data set!**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb58d9",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Problem 6</span>\n",
    "The length of songs is given in miliseconds. Convert the values to seconds. Then, examine the resulting distribution. Finally, answer these questions:\n",
    "\n",
    "1. When you converted the values to seconds, did you perform a re-expression, shift, or rescaling of the duration_ms distribution?\n",
    "2. What is the average length for a song to be? Write your answer in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc1bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f61611",
   "metadata": {},
   "source": [
    "**Your markdown here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d929002",
   "metadata": {},
   "source": [
    "# Is it Normal?\n",
    "Remember, you should only calculate the standard deviation of a normal distributions (roughly symmetric and unimodal, looks like a bell). Yes, you can draw the histogram to visually confirm if it is \"normal enough\", but is there a better way to tell?\n",
    "\n",
    "There‚Äôs a more specialized graph that can help you to decide whether a distribution is normal -- it's called the **Normality Probability Plot**. If the distribution is \"normal enough\", the Normality Probility Plot will show a straight, diagonal line. This graph is usually able to show deviations from normal more clearly than the corresponding histogram, but it‚Äôs usually easier to understand how a distribution fails to be normal by looking at its histogram. So the Normality Probability Plot is just another tool in your toolbox that you can use to make a decision when the answer is debateable (and it often is!). \n",
    "\n",
    "Let's take a look at an example about car fuel efficienty to understand this better. \n",
    "\n",
    "![Normality Probability Plot - Gas](https://raw.githubusercontent.com/SSpindt/AI/main/Semester%201/Problem%20Set%20Images/NormalityProbPlot1.png)\n",
    "\n",
    "The overall pattern of the Normal probability plot is straight. The two trailing low values correspond to the values in the histogram that trail off the low end. They‚Äôre not quite in line with the rest of the data set. The Normal probability plot shows us that they‚Äôre a bit lower than we‚Äôd expect of the lowest two values in a truly normal distribution.\n",
    "\n",
    "In contrast, the Normal probability plot of the men‚Äôs Weights from the previous section is far from straight. The weights are skewed to the high end, and the plot is curved. We‚Äôd conclude from these pictures that approximations using the Empircal Rule (68‚Äì95‚Äì99.7 Rule) for these data would not be very accurate because the Empircal Rule only applies to normal distributions.\n",
    "\n",
    "![Normality Probability Plot - Weight](https://raw.githubusercontent.com/SSpindt/AI/main/Semester%201/Problem%20Set%20Images/NormalityProbPlot2.png)\n",
    "\n",
    "Why does the Normal probability plot work like that? Imagine you looked at 100 fuel efficiency measures for the Ms. Spindt's Honda. The smallest of these has a z-score of -3.16. A normal distribution can tell us what value to expect for the smallest z-score in a batch of 100 if it were normal. That turns out to be -2.58. So our first data value is smaller than we would expect from the \"normal\" value.\n",
    "\n",
    "We can continue this and ask a similar question for each value. For example, the 14th-smallest fuel efficiency has a z-score of almost exactly -1, and that‚Äôs just what we should expect (well, -1.1 to be exact). A Normal probability plot takes each data value and plots it against the z-score you‚Äôd expect that point to have if the distribution were perfectly Normal.\n",
    "\n",
    "When the values match up well, the line is straight. If one or two points are surprising from the Normal‚Äôs point of view, they don‚Äôt line up. When the entire distribution is skewed or different from normal in some other way, the values don‚Äôt match up very well at all and the plot bends.\n",
    "\n",
    "It turns out to be tricky to find the values we expect. They‚Äôre called \"Normal scores\", but you can‚Äôt easily look them up. That‚Äôs why probability plots are best made with technology and not by hand.\n",
    "\n",
    "The best advice on using Normal probability plots is to see whether they are straight. If so, then your data look like data from a Normal model. If not, make a histogram to understand how they differ from normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3609443f",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Your Turn</span>\n",
    "Please solve the following problems using Python, Markdown, and the latest [Spotify data set](https://drive.google.com/drive/folders/1nGqifcJXrpsEDCkAiJMnQkrGiOgD93Qv?usp=drive_link) we have been working with in the last few classes. It is the same data set used in the last problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b1e7d",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Problem 7</span>\n",
    "Examine the distribution for a track popularity. Create a Normality Probability Plot to see how \"normal\" it is. You need another Python library to do this -- it's called [SciPy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.probplot.html). I don't expect you to understand this code but I would like you to be able to interpret the plot. Finally, answer these questions:\n",
    "\n",
    "1. Is track popularity normal? Justify your answer.\n",
    "2. Which genre of music produces the most popular songs? Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb26dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normality Probability Plot Code\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "(osm, osr), (slope, intercept, r) = stats.probplot(df[\"track_popularity\"])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(osm, osr, 'o', markersize=5)\n",
    "plt.plot(osm, slope * osm + intercept, 'r', linewidth=2)\n",
    "plt.title('Normality Probability Plot - Track Popularity')\n",
    "plt.xlabel('Normal Scores')\n",
    "plt.ylabel('Quantiles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133a212",
   "metadata": {},
   "source": [
    "**Your markdown here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a071f7",
   "metadata": {},
   "source": [
    "## You are all done! Time to submit!\n",
    "Please put this notebook in your repository before you commit and push it to your GitHub account. Then complete the brief survey on Schoology in order to submit. You will provide me with your GitHub username and the URL to your repository in this survey so that I can access your work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
